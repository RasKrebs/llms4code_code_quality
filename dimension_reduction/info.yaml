### General Application Domain Info
domain: Data Science
application: Dimension Reduction
algorithm: Principal Componenet Analysis (PCA)

long_prompt: """
Create a python class called PrincipalComponentAnalysis that implements the Principal Component Analysis algorithm from scratch.  During initalization the class should take two arguments:
* n_components, if not specified it should default to all. 
* decomposition_method, which should be either 'eigen' or 'svd'. If not specified it should default to 'eigen'. Add a fit method that takes one input, X, that is either a numpy array, pandas dataframe or a list of lists as input. The fit method  should compute the eigen values and eigen vectors (components) for the inputted data, and stores them on the object. If n_components is specified the fit method should store only top n_components eigen values and eigen vectors. In the fit, the method should also compute the explained variance ratio, and cumulative sum of explained variance ratio for each component and store it on the object. Also add a transform method that takes one input, X, that is either a numpy array, pandas dataframe or a list of lists as input. The transform method should project the inputted data onto the components and return the projected data. The transform method should also take an optional argument, n_components, that specifies the number of components to project onto. If n_components is not specified it should default to all. The last method to add is a fit_transform method that takes one input, X, that is either a numpy array, pandas dataframe or a list of lists as input. Like transform, this method should also take an optional n_components, specifying n_components, 
otherwise use all. The fit_transform method should call the fit method and then the transform method. 

Make sure to add documentation to the class and methods in the form of docstrings and comments. Also make sure to add type hints to the methods.
"""

medium_prompt: """
Create a python class called PrincipalComponentAnalysis that implements the Principal Component Analysis algorithm from scratch. It should have three methods, fit, transform and fit_transform. Two arguments should be able to be passed, first is n_components which specifies the number of components to use. If n_components is not specified it should default to all. Second is decomposition_method, which should be either 'eigen' or 'svd'. If not specified it should default to 'eigen'.

Make sure to add documentation to the class and methods in the form of docstrings and comments. Also make sure to add type hints to the methods.
"""

small_prompt: """
Implement prinicpal component analysis from scratch, that can be used with either eigen decomposition and singular value decomposition. 
"""

# Model Specific 
GPT-3.5:
  path: ../GPT_35/
  version: gpt-3.5-turbo (Jan 2024)
  data_collection_time: 01/10/2024
  additional_prompts: # Add here additional prompts used during data collection
  additional_info: # Add here additional info used during data collection
  documentation: ../GPT_35/documentation/

GPT-4:
  path: ../GPT4/
  version: gpt-4-turbo (Jan 2024)
  data_collection_time: 01/10/2024
  additional_prompts: # Add here additional prompts used during data collection
  additional_info: # Add here additional info used during data collection
  documentation: ../GPT4/documentation/

Codex:
  path: ../codex/
  version: Github Copilot (Jan 2024)
  data_collection_time: 01/10/2024
  additional_prompts: # Add here additional prompts used during data collection
  additional_info: # Add here additional info used during data collection
  documentation: ../codex/documentation/

DeepSeeker-Coder:
  path: ../DeepSeeker-Coder/
  version: DeepSeek-Coder-33
  data_collection_time: 01/10/2024
  additional_prompts: # Add here additional prompts used during data collection
  additional_info: Used DeepSeeker Coder, not the newly available DeepSeeker Chat
  documentation: ../codex/documentation/

Gemini:
  path: ../Gemini/
  version: Gemini Pro (Accessed through Bard Jan 2024)
  data_collection_time: 01/10/2024
  additional_prompts: 
    - The code is not complete
    - It seems the response can't be done within the max token you have selected
  additional_info: Gemini Pro was accessed through Bard. For the long prompt, a maximum token enforced by Bard limited the ability to produce a complete response. Two follow up prompts, described above was used for a more complete response.
  documentation: ../codex/documentation/

Tabnine:
  path: ../Tabnine/
  version: Unknown
  data_collection_time: 01/11/2024
  additional_prompts: # None
  additional_info: 
    - The medium prompt answer did not import the necessary libraries, so these were added manually
    - Unlike other methods, Tabnine also added additional methods such as built in class-representation, __repr__, methdo
  documentation: ../codex/documentation/