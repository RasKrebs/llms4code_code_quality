
----long----

Filename: memory_usage/long_memory_usage_version.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    28    168.3 MiB    168.3 MiB           1       @profile
    29                                             def __init__(self, n_components=None, decomposition_method='eigen'):
    30    168.3 MiB      0.0 MiB           1           self.n_components = n_components
    31    168.3 MiB      0.0 MiB           1           self.decomposition_method = decomposition_method
    32                                         
    33                                                 # Eigen values and eigen vectors of the covariance matrix
    34    168.3 MiB      0.0 MiB           1           self.eigenvalues = None
    35    168.3 MiB      0.0 MiB           1           self.eigenvectors = None
    36                                         
    37                                                 # Explained variance ratio and cumulative sum of explained variance ratio
    38    168.3 MiB      0.0 MiB           1           self.explained_variance_ratio = None
    39    168.3 MiB      0.0 MiB           1           self.cumulative_explained_variance_ratio = None


Filename: memory_usage/long_memory_usage_version.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    41    168.3 MiB    168.3 MiB           1       @profile
    42                                             def fit(self, X):
    43                                                 """
    44                                                 Fits the PCA model to the data.
    45                                         
    46                                                 Parameters:
    47                                                 X: (numpy.ndarray, pandas.DataFrame, list)
    48                                                     The data to fit the model to. Can be a numpy array, pandas DataFrame, or a list of lists.
    49                                                 """
    50                                         
    51                                                 # Check if X is a valid data format
    52    168.3 MiB      0.0 MiB           1           if not isinstance(X, (np.ndarray, pd.DataFrame, list)):
    53                                                     raise TypeError('X must be a numpy.ndarray, pandas.DataFrame, or a list of lists.')
    54                                         
    55                                                 # Check if X is a 2D array
    56    168.3 MiB      0.0 MiB           1           if not (isinstance(X, np.ndarray) and X.ndim == 2):
    57                                                     raise ValueError('X must be a 2D array.')
    58                                         
    59                                                 # Check if X contains numerical data
    60    168.3 MiB -109981.4 MiB       10001           for row in X:
    61    168.3 MiB -22321556.2 MiB     2030000               if not all(isinstance(x, (int, float)) for x in row):
    62                                                         raise ValueError('X must contain numerical data.')
    63                                         
    64                                                 # Standardize the data
    65    148.4 MiB    -19.8 MiB           1           X = StandardScaler().fit_transform(X)
    66                                         
    67                                                 # Compute the covariance matrix
    68    156.8 MiB      8.4 MiB           1           covariance_matrix = np.cov(X.T)
    69                                         
    70                                                 # Calculate the eigen values and eigen vectors
    71    156.8 MiB      0.0 MiB           1           if self.decomposition_method == 'eigen':
    72    158.0 MiB      1.2 MiB           1               eigen_values, eigen_vectors = np.linalg.eig(covariance_matrix)
    73                                                 elif self.decomposition_method == 'svd':
    74                                                     U, S, Vh = np.linalg.svd(covariance_matrix)
    75                                                     eigen_values = S.astype(float)
    76                                                     eigen_vectors = Vh.T.astype(float)
    77                                                 else:
    78                                                     raise ValueError('Invalid decomposition_method: {}.'.format(self.decomposition_method))
    79                                         
    80                                                 # Sort eigen values and eigen vectors in descending order based on eigen values
    81    158.1 MiB      0.1 MiB           1           sorted_idx = np.argsort(eigen_values)[::-1]
    82    158.1 MiB      0.0 MiB           1           eigen_values = eigen_values[sorted_idx]
    83    158.2 MiB      0.1 MiB           1           eigen_vectors = eigen_vectors[sorted_idx]
    84                                         
    85                                                 # Keep only the top n_components
    86    158.2 MiB      0.0 MiB           1           if self.n_components is not None:
    87                                                     eigen_values = eigen_values[:self.n_components]
    88                                                     eigen_vectors = eigen_vectors[:self.n_components]
    89                                         
    90                                                 # Compute explained variance ratio and cumulative sum of explained variance ratio
    91    158.2 MiB      0.0 MiB           1           explained_variance_ratio = eigen_values / np.sum(eigen_values)
    92    158.2 MiB      0.0 MiB           1           cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio)
    93                                         
    94                                                 # Store the computed values
    95    158.2 MiB      0.0 MiB           1           self.eigenvalues = eigen_values
    96    158.2 MiB      0.0 MiB           1           self.eigenvectors = eigen_vectors
    97    158.2 MiB      0.0 MiB           1           self.explained_variance_ratio = explained_variance_ratio
    98    158.2 MiB      0.0 MiB           1           self.cumulative_explained_variance_ratio = cumulative_explained_variance_ratio


Filename: memory_usage/long_memory_usage_version.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   100    161.4 MiB    161.4 MiB           1       @profile
   101                                             def transform(self, X):
   102                                                 """
   103                                                 Projects the data onto the principal components.
   104                                             
   105                                                 Parameters:
   106                                                 X: (numpy.ndarray, pandas.DataFrame, list)
   107                                                     The data to transform. Can be a numpy array, pandas DataFrame, or a list of lists.
   108                                             
   109                                                 Returns:
   110                                                     (numpy.ndarray)
   111                                                         The projected data.
   112                                                 """
   113                                             
   114                                                 # Check if X is a valid data format
   115    161.4 MiB      0.0 MiB           1           if not isinstance(X, (np.ndarray, pd.DataFrame, list)):
   116                                                     raise TypeError('X must be a numpy.ndarray, pandas.DataFrame, or list of lists.')
   117                                             
   118                                                 # Check if X is a 2D array
   119    161.4 MiB      0.0 MiB           1           if not (isinstance(X, np.ndarray) and X.ndim == 2):
   120                                                     raise ValueError('X must be a 2D array.')
   121                                             
   122                                                 # Check if X contains numerical data
   123    161.4 MiB      0.0 MiB       10001           for row in X:
   124    161.4 MiB      0.0 MiB     2030000               if not all(isinstance(x, (int, float)) for x in row):
   125                                                         raise ValueError('X must contain numerical data.')
   126                                             
   127                                                 # Transform the data
   128    169.1 MiB      7.8 MiB           1           transformed_data = np.dot(X, self.eigenvectors.T)
   129                                             
   130    169.1 MiB      0.0 MiB           1           return transformed_data


CPU Usage: 22.150000000000002%

----medium----

Filename: memory_usage/medium_memory_usage_version.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    26    120.3 MiB    120.3 MiB           1       @profile
    27                                             def __init__(self, n_components=None, decomposition_method='eigen'):
    28    120.3 MiB      0.0 MiB           1           self.n_components = n_components
    29    120.3 MiB      0.0 MiB           1           self.decomposition_method = decomposition_method


Filename: memory_usage/medium_memory_usage_version.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    31    120.3 MiB    120.3 MiB           1       @profile
    32                                             def fit(self, X: np.ndarray) -> None:
    33                                                 """
    34                                                 Fits the PCA model to the given data.
    35                                         
    36                                                 Args:
    37                                                     X: (np.ndarray) Data to be transformed.
    38                                                 """
    39                                                 # Check if data is a numpy array
    40    120.3 MiB      0.0 MiB           1           if not isinstance(X, np.ndarray):
    41                                                     raise TypeError('Data must be a numpy.ndarray')
    42                                         
    43                                                 # Check dimensions
    44    120.3 MiB      0.0 MiB           1           if X.ndim != 2:
    45                                                     raise ValueError('Data must be a 2D matrix')
    46                                         
    47                                                 # Check if n_components is an integer and greater than 0
    48    120.3 MiB      0.0 MiB           1           if self.n_components is not None and not isinstance(self.n_components, int) or self.n_components < 1:
    49                                                     raise ValueError('n_components must be an integer greater than 0')
    50                                         
    51                                                 # Check if decomposition_method is valid
    52    120.3 MiB      0.0 MiB           1           if self.decomposition_method not in ['eigen', 'svd']:
    53                                                     raise ValueError("Invalid decomposition_method: must be either 'eigen' or 'svd'")
    54                                         
    55                                                 # Calculate mean and covariance matrix
    56    120.3 MiB      0.0 MiB           1           self.mean = np.mean(X, axis=0)
    57    128.2 MiB      7.9 MiB           1           self.covariance_matrix = np.cov(X.T)
    58                                         
    59                                                 # Perform dimensionality reduction using specified method
    60    128.2 MiB      0.0 MiB           1           if self.decomposition_method == 'eigen':
    61    129.2 MiB      1.0 MiB           1               self.eigvals, self.eigvecs = np.linalg.eig(self.covariance_matrix)
    62                                                 elif self.decomposition_method == 'svd':
    63                                                     U, S, Vh = np.linalg.svd(self.covariance_matrix)
    64                                                     self.eigvals = S**2
    65                                                     self.eigvecs = Vh.T
    66                                         
    67                                                 # Sort eigenvectors by descending eigenvalues
    68    129.2 MiB      0.0 MiB           1           indices = np.argsort(self.eigvals)[::-1]
    69    129.2 MiB      0.0 MiB           1           self.eigvals = self.eigvals[indices]
    70    129.2 MiB      0.0 MiB           1           self.eigvecs = self.eigvecs[indices]
    71                                         
    72                                                 # Truncate eigenvectors to desired number of components
    73    129.2 MiB      0.0 MiB           1           if self.n_components is not None:
    74    129.2 MiB      0.0 MiB           1               self.eigvals = self.eigvals[:self.n_components]
    75    129.2 MiB      0.0 MiB           1               self.eigvecs = self.eigvecs[:, :self.n_components]


Filename: memory_usage/medium_memory_usage_version.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    78    129.2 MiB    129.2 MiB           1       @profile
    79                                             def transform(self, X: np.ndarray) -> np.ndarray:
    80                                                 """
    81                                                 Transforms the given data using the fitted PCA model.
    82                                         
    83                                                 Args:
    84                                                     X: (np.ndarray) Data to be transformed.
    85                                         
    86                                                 Returns:
    87                                                     np.ndarray: Transformed data in the lower-dimensional space.
    88                                                 """
    89                                         
    90                                                 # Check if data is a numpy array
    91    129.2 MiB      0.0 MiB           1           if not isinstance(X, np.ndarray):
    92                                                     raise TypeError('Data must be a numpy.ndarray')
    93                                         
    94                                                 # Check dimensions
    95    129.2 MiB      0.0 MiB           1           if X.ndim != 2:
    96                                                     raise ValueError('Data must be a 2D matrix')
    97                                         
    98                                                 # Standardize data
    99    136.9 MiB      7.6 MiB           1           Z = X - self.mean
   100                                         
   101                                                 # Project data onto principal components
   102    145.0 MiB      8.1 MiB           1           transformed_data = Z @ self.eigvecs
   103                                         
   104    145.0 MiB      0.0 MiB           1           return transformed_data


CPU Usage: 21.849999999999998%

----small----

Filename: memory_usage/small_memory_usage_version.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    16     73.0 MiB     73.0 MiB           1   @profile
    17                                         def pca(data, method='eig'):
    18                                             """
    19                                             Principal Component Analysis (PCA)
    20                                         
    21                                             Parameters:
    22                                             data (numpy.ndarray): The data to be analyzed.
    23                                             method (str): The method to be used for dimensionality reduction, either 'eig' for eigen decomposition or 'svd' for singular value decomposition.
    24                                         
    25                                             Returns:
    26                                             numpy.ndarray: The reduced data.
    27                                             """
    28                                         
    29                                             # Check the input data
    30     73.0 MiB      0.0 MiB           1       assert isinstance(data, np.ndarray), 'The input data must be a numpy.ndarray.'
    31     73.0 MiB      0.0 MiB           1       assert data.ndim >= 2, 'The input data must be at least a 2D array.'
    32                                         
    33                                             # Center the data
    34     73.1 MiB      0.0 MiB           1       data_mean = np.mean(data, axis=0)
    35     80.8 MiB      7.7 MiB           1       centered_data = data - data_mean
    36                                         
    37                                             # Calculate the covariance matrix
    38     88.8 MiB      8.0 MiB           1       covariance_matrix = np.cov(centered_data.T)
    39                                         
    40                                             # Perform dimensionality reduction
    41     88.8 MiB      0.0 MiB           1       if method == 'eig':
    42                                                 # Calculate the eigenvalues and eigenvectors of the covariance matrix
    43     89.8 MiB      1.0 MiB           1           eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)
    44                                         
    45                                                 # Sort the eigenvalues and eigenvectors in descending order
    46     89.8 MiB      0.0 MiB           1           idx = eigenvalues.argsort()[::-1]
    47     89.8 MiB      0.0 MiB           1           eigenvalues = eigenvalues[idx]
    48     89.8 MiB      0.0 MiB           1           eigenvectors = eigenvectors[:, idx]
    49                                         
    50                                                 # Choose the top k eigenvectors as the principal components
    51     89.8 MiB      0.0 MiB           1           k = min(data.shape[1], len(eigenvalues))
    52     89.8 MiB      0.0 MiB           1           principal_components = eigenvectors[:, :k]
    53                                         
    54                                             elif method == 'svd':
    55                                                 # Perform singular value decomposition
    56                                                 u, s, vh = np.linalg.svd(centered_data)
    57                                         
    58                                                 # Choose the top k singular values as the principal components
    59                                                 k = min(data.shape[1], len(s))
    60                                                 principal_components = vh[:, :k].T
    61                                         
    62                                             else:
    63                                                 raise ValueError('Invalid method: {}'.format(method))
    64                                         
    65                                             # Reduce the data to the principal components
    66    105.2 MiB     15.4 MiB           1       reduced_data = np.dot(centered_data, principal_components.T)
    67                                         
    68    105.2 MiB      0.0 MiB           1       return reduced_data


CPU Usage: 21.875%
